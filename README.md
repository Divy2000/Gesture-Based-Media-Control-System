# Hand Gesture Recognition for Human-Computer Interaction

This project demonstrates a gesture-based media control system that allows users to control media playback with hand gestures. It includes functionalities for play/pause, volume up, and volume down through a gesture recognition model integrated with media controls.

## Project Highlights

- **Dataset**: Curated a dataset of hand gestures for media control functions (play/pause, volume up, volume down).
- **Preprocessing**: Applied preprocessing and augmentation techniques to enhance gesture recognition accuracy to 95%.
- **Model Development**: Developed a gesture recognition model and integrated it with media controls for hands-free operation.

## Demo Link 
[Demo of Hand Gesture Recognition For Human Computer Interaction](https://youtu.be/TA2x1n3wu9c)

## Folder Structure
```
ğŸ“¦AI model
 â”£ ğŸ“‚datasets
 â”ƒ â”£ ğŸ“‚Down
 â”ƒ â”£ ğŸ“‚Ideal
 â”ƒ â”£ ğŸ“‚Stop
 â”ƒ â”— ğŸ“‚Up
 â”£ ğŸ“‚dict
 â”ƒ â”£ ğŸ“œdict_d.pkl
 â”ƒ â”£ ğŸ“œdict_e.pkl
 â”ƒ â”£ ğŸ“œdict_ld.pkl
 â”ƒ â”— ğŸ“œdict_le.pkl
 â”£ ğŸ“‚model
 â”ƒ â”£ ğŸ“‚assets
 â”ƒ â”£ ğŸ“‚variables
 â”ƒ â”£ ğŸ“œkeras_metadata.pb
 â”ƒ â”— ğŸ“œsaved_model.pb
 â”£ ğŸ“‚numpy_data
 â”ƒ â”£ ğŸ“œx_test.npy
 â”ƒ â”£ ğŸ“œx_train.npy
 â”ƒ â”£ ğŸ“œx_val.npy
 â”ƒ â”£ ğŸ“œy_test.npy
 â”ƒ â”£ ğŸ“œy_train.npy
 â”ƒ â”— ğŸ“œy_val.npy
 â”£ ğŸ“œcamera_pred.py
 â”£ ğŸ“œDatabase.py
 â”£ ğŸ“œdriver.py
 â”£ ğŸ“œgesture.py
 â”£ ğŸ“œGet_class.py
 â”£ ğŸ“œget_features.py
 â”£ ğŸ“œget_mobilenet.py
 â”£ ğŸ“œmodel.py
 â”— ğŸ“œtrain_test_split.py
```
